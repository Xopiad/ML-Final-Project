{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autism Screening Adult Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description: <br>**\n",
    "Data relates to Autism Spectrum Disorder (ASD) screening of adults containing 20 features. The features are composed of 10 behavioral and 10 individual characteristics that are considered effective for ASD detection. The dataset consists of 704 samples, each having 20 attributes and their corresponding label for ASD detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original Dataset Attributes:**\n",
    "\n",
    "*Note: Attributes 1-10 are screening responses to a behavorial questionnaire. The rest are individual characteristics*\n",
    "\n",
    "**Attribute 1: A1_Score<br>**\n",
    "Decription: \"I often notice small sounds when others do not\"<br>\n",
    "Values: Binary integer {0,1} or \"No, Yes\" \n",
    "\n",
    "**Attribute 2: A2_score<br>**\n",
    "Description: \"I usually concentrate more on the whole picture, rather than the small details\"<br>\n",
    "Values: Binary integer {0,1} or \"No, Yes\" \n",
    "\n",
    "**Attribute 3: A3_Score<br>**\n",
    "Description: \"I find it easy to do more than one thing at once\"<br>\n",
    "Values: Binary integer {0,1} or \"No, Yes\" \n",
    "\n",
    "**Attribute 4: A4_Score<br>**\n",
    "Description: \"If there is an interruption, I can switch back to what I was doing very quickly\"<br>\n",
    "Values: Binary integer {0,1} or \"No, Yes\" \n",
    "\n",
    "**Attribute 5: A5_Score<br>**\n",
    "Description: \"I find it easy to read between the lines when someone is talking to me\"<br>\n",
    "Values: Binary integer {0,1} or \"No, Yes\" \n",
    "\n",
    "**Attribute 6: A6_Score<br>**\n",
    "Description: \"I know how to tell if someone listening to me is getting bored\"<br>\n",
    "Values: Binary integer {0,1} or \"No, Yes\" \n",
    "\n",
    "**Attribute 7: A7_Score<br>**\n",
    "Description: \"When I'm reading a story I find it difficult to workout the character's intentions\"<br>\n",
    "Values: Binary integer {0,1} or \"No, Yes\" \n",
    "\n",
    "**Attribute 8: A8_Score<br>**\n",
    "Description: \"I like to collect information about categories of things\"<br>\n",
    "Values: Binary integer {0,1} or \"No, Yes\"\n",
    "\n",
    "**Attribute 9: A9_Score<br>**\n",
    "Description: \"I find it easy to workout what someone is thinking or feeling just by looking at their face\"<br>\n",
    "Values: Binary integer {0,1} or \"No, Yes\" \n",
    "\n",
    "**Attribute 10: A10_Score<br>**\n",
    "Description: \"I find it difficult to workout people's intentions\"<br>\n",
    "Values: Binary integer {0,1} or \"No, Yes\" \n",
    "\n",
    "**Attribute 11: age<br>**\n",
    "Description: Age (years)<br>\n",
    "Values: Numeric integers \n",
    "\n",
    "**Attribute 12: gender<br>**\n",
    "Description: Gender<br>\n",
    "Values: {'f', 'm'} strings for female, male respectively \n",
    "\n",
    "**Attribute 13: ethnicity<br>**\n",
    "Description: Ethnicity<br>\n",
    "Values: common ethnicity strings (ex: \"Turkish) \n",
    "\n",
    "**Attribute 14: jundice<br>**\n",
    "Description: Born with jaundice<br>\n",
    "Values: {'no', 'yes'} strings \n",
    "\n",
    "**Attribute 15: autism <br>**\n",
    "Description: Family member has autism<br>\n",
    "Values: {'no', 'yes'} strings \n",
    "\n",
    "**Attribute 16: country_of_res<br>**\n",
    "Description: Country of residence<br>\n",
    "Values: String of country name (ex: 'United States')\n",
    "\n",
    "**Attribute 17: used_app_before<br>**\n",
    "Description: Whether user has used screening app<br>\n",
    "Values: {'no', 'yes'} strings \n",
    "\n",
    "**Attribute 18: result<br>**\n",
    "Description: Screening app score based on algorithm<br>\n",
    "Values: numeric integer\n",
    "\n",
    "**Attribute 19: age_desc<br>**\n",
    "Description: Age category<br>\n",
    "Values: String (ex: \"18 and over\")\n",
    "\n",
    "**Attribute 20: relation<br>**\n",
    "Description: Relation to person completing test<br>\n",
    "Values: String ex('Parent', 'Self', 'Caregiver', etc.) \n",
    "\n",
    "**Label 21: Class/ASD<br>**\n",
    "Description: Label for detection of ASD<br>\n",
    "Values: {'NO', 'YES'} strings \n",
    "\n",
    "\n",
    "*This can be confirmed from the loaded 'meta' printed below*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing - Autism Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Meta Dataset: adult-weka.filters.unsupervised.attribute.NumericToNominal-Rfirst-10\n",
      "\tA1_Score's type is nominal, range is ('0', '1')\n",
      "\tA2_Score's type is nominal, range is ('0', '1')\n",
      "\tA3_Score's type is nominal, range is ('0', '1')\n",
      "\tA4_Score's type is nominal, range is ('0', '1')\n",
      "\tA5_Score's type is nominal, range is ('0', '1')\n",
      "\tA6_Score's type is nominal, range is ('0', '1')\n",
      "\tA7_Score's type is nominal, range is ('0', '1')\n",
      "\tA8_Score's type is nominal, range is ('0', '1')\n",
      "\tA9_Score's type is nominal, range is ('0', '1')\n",
      "\tA10_Score's type is nominal, range is ('0', '1')\n",
      "\tage's type is numeric\n",
      "\tgender's type is nominal, range is ('f', 'm')\n",
      "\tethnicity's type is nominal, range is ('White-European', 'Latino', 'Others', 'Black', 'Asian', \"'Middle Eastern '\", 'Pasifika', \"'South Asian'\", 'Hispanic', 'Turkish', 'others')\n",
      "\tjundice's type is nominal, range is ('no', 'yes')\n",
      "\taustim's type is nominal, range is ('no', 'yes')\n",
      "\tcontry_of_res's type is nominal, range is (\"'United States'\", 'Brazil', 'Spain', 'Egypt', \"'New Zealand'\", 'Bahamas', 'Burundi', 'Austria', 'Argentina', 'Jordan', 'Ireland', \"'United Arab Emirates'\", 'Afghanistan', 'Lebanon', \"'United Kingdom'\", \"'South Africa'\", 'Italy', 'Pakistan', 'Bangladesh', 'Chile', 'France', 'China', 'Australia', 'Canada', \"'Saudi Arabia'\", 'Netherlands', 'Romania', 'Sweden', 'Tonga', 'Oman', 'India', 'Philippines', \"'Sri Lanka'\", \"'Sierra Leone'\", 'Ethiopia', \"'Viet Nam'\", 'Iran', \"'Costa Rica'\", 'Germany', 'Mexico', 'Russia', 'Armenia', 'Iceland', 'Nicaragua', \"'Hong Kong'\", 'Japan', 'Ukraine', 'Kazakhstan', 'AmericanSamoa', 'Uruguay', 'Serbia', 'Portugal', 'Malaysia', 'Ecuador', 'Niger', 'Belgium', 'Bolivia', 'Aruba', 'Finland', 'Turkey', 'Nepal', 'Indonesia', 'Angola', 'Azerbaijan', 'Iraq', \"'Czech Republic'\", 'Cyprus')\n",
      "\tused_app_before's type is nominal, range is ('no', 'yes')\n",
      "\tresult's type is numeric\n",
      "\tage_desc's type is nominal, range is (\"'18 and more'\",)\n",
      "\trelation's type is nominal, range is ('Self', 'Parent', \"'Health care professional'\", 'Relative', 'Others')\n",
      "\tClass/ASD's type is nominal, range is ('NO', 'YES')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io.arff import loadarff\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Loading arff file\n",
    "Autism_Adult, meta = loadarff('Autism-Adult-Data.arff')\n",
    "\n",
    "# meta contains info about arff file (attrs)\n",
    "print(\"Loaded Meta\", meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the data matrix**<br>\n",
    "From the Autism_Adult records the data of the arff file, accessible by attribute names. When add the Autism_Adult data to matrix, each element in the matrix has the type numpy.bytes_, therefore need to convert to int or str type depending on each attribute type so data matrix can be manipulated without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn Autism_Adult into matrix of data\n",
    "Autism_Adult_data = np.array(Autism_Adult[meta.names()[0]].astype(int, copy = True)).reshape(704,1)\n",
    "\n",
    "# Attributes 1-10 are integers -> add to Autism_Adult_data\n",
    "for i in range(1,11):\n",
    "    Autism_Adult_data = np.c_[Autism_Adult_data, np.array(Autism_Adult[meta.names()[i]]).astype(int, copy = True)]\n",
    "    \n",
    "# Attributes 11-16 are strings -> add to Autism_Adult_data\n",
    "for i in range(11,17):\n",
    "    Autism_Adult_data = np.c_[Autism_Adult_data, np.array(Autism_Adult[meta.names()[i]]).astype(str, copy = True)]\n",
    "    \n",
    "# Attribute 17 is an integer -> add to Autism_Adult_data\n",
    "Autism_Adult_data = np.c_[Autism_Adult_data, np.array(Autism_Adult[meta.names()[17]]).astype(int, copy = True)]\n",
    "\n",
    "# Attributes 18-21 are strings -> add to Autism_Adult_data\n",
    "for i in range(18,len(meta.names())):\n",
    "    Autism_Adult_data = np.c_[Autism_Adult_data, np.array(Autism_Adult[meta.names()[i]]).astype(str, copy = True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating pandas DataFrame for easier manipulation**<br><br>\n",
    "Printing the pre-cleaned up DataFrame below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>contry_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>result</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>'United States'</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>'18 and more'</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>Latino</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>'18 and more'</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>Latino</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Spain</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>'18 and more'</td>\n",
       "      <td>Parent</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>'United States'</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>'18 and more'</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>'18 and more'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>Others</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>'United States'</td>\n",
       "      <td>no</td>\n",
       "      <td>9</td>\n",
       "      <td>'18 and more'</td>\n",
       "      <td>Self</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>Black</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>'United States'</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>'18 and more'</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>'New Zealand'</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>'18 and more'</td>\n",
       "      <td>Parent</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>'United States'</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>'18 and more'</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>Asian</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>'18 and more'</td>\n",
       "      <td>'Health care professional'</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score  \\\n",
       "0        1        1        1        1        0        0        1        1   \n",
       "1        1        1        0        1        0        0        0        1   \n",
       "2        1        1        0        1        1        0        1        1   \n",
       "3        1        1        0        1        0        0        1        1   \n",
       "4        1        0        0        0        0        0        0        1   \n",
       "5        1        1        1        1        1        0        1        1   \n",
       "6        0        1        0        0        0        0        0        1   \n",
       "7        1        1        1        1        0        0        0        0   \n",
       "8        1        1        0        0        1        0        0        1   \n",
       "9        1        1        1        1        0        1        1        1   \n",
       "\n",
       "  A9_Score A10_Score    ...    gender       ethnicity jundice austim  \\\n",
       "0        0         0    ...         f  White-European      no     no   \n",
       "1        0         1    ...         m          Latino      no    yes   \n",
       "2        1         1    ...         m          Latino     yes    yes   \n",
       "3        0         1    ...         f  White-European      no    yes   \n",
       "4        0         0    ...         f             NaN      no     no   \n",
       "5        1         1    ...         m          Others     yes     no   \n",
       "6        0         0    ...         f           Black      no     no   \n",
       "7        1         0    ...         m  White-European      no     no   \n",
       "8        1         1    ...         m  White-European      no     no   \n",
       "9        1         0    ...         m           Asian     yes    yes   \n",
       "\n",
       "     contry_of_res used_app_before result       age_desc  \\\n",
       "0  'United States'              no      6  '18 and more'   \n",
       "1           Brazil              no      5  '18 and more'   \n",
       "2            Spain              no      8  '18 and more'   \n",
       "3  'United States'              no      6  '18 and more'   \n",
       "4            Egypt              no      2  '18 and more'   \n",
       "5  'United States'              no      9  '18 and more'   \n",
       "6  'United States'              no      2  '18 and more'   \n",
       "7    'New Zealand'              no      5  '18 and more'   \n",
       "8  'United States'              no      6  '18 and more'   \n",
       "9          Bahamas              no      8  '18 and more'   \n",
       "\n",
       "                     relation Class/ASD  \n",
       "0                        Self        NO  \n",
       "1                        Self        NO  \n",
       "2                      Parent       YES  \n",
       "3                        Self        NO  \n",
       "4                         NaN        NO  \n",
       "5                        Self       YES  \n",
       "6                        Self        NO  \n",
       "7                      Parent        NO  \n",
       "8                        Self        NO  \n",
       "9  'Health care professional'       YES  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to pandas DataFrame for easier manipulation \n",
    "Autism_frame = pd.DataFrame(data = Autism_Adult_data, columns = meta.names()[:])\n",
    "\n",
    "# Replace '?' with NaN, help to find columns of missing values\n",
    "Autism_frame.replace('?', np.NaN, inplace = True)\n",
    "\n",
    "# Printing first 10 rows of data frame\n",
    "Autism_frame.head(10)\n",
    "\n",
    "# Dimension of pandas DataFrame\n",
    "#print(Autism_frame.shape) # 704 by 21 -> 704 sampes, 20 attributes, last column holds labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Clean up discussion**:<br>\n",
    "1) We correct the attribute names to reduce chances of spelling errors (example: original attribute name for Jaundice was jundice)<br>\n",
    "2) Attribute 'ethnicity' had duplicate value of \"others\" and \"Others\" so that was merged into one being \"Others\"<br>\n",
    "3) Outlier in age fixed (likely a typo '383' -> '38')<br>\n",
    "\n",
    "<br>**Reduction discussion**:<br>\n",
    "1) From the meta above, the attribute 'age_desc' has only one level which is \"18 and more\". This has no signifance so it is dropped<br>\n",
    "2) ** ALSO REMOVED ATTRIBUTES: country, used app before, result **<br>\n",
    "3) We decided to remove all samples with missing values. The missing values were predominantly categorical (ex: ethnicity, relation). It does not make sense to assign replacement values with the mean or median for non numeric variables. <br> <br>\n",
    "\n",
    "**The cleaned up pandas DataFrame can be seen printed below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jaundice</th>\n",
       "      <th>autism</th>\n",
       "      <th>relation</th>\n",
       "      <th>ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>m</td>\n",
       "      <td>Latino</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>m</td>\n",
       "      <td>Latino</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Parent</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>m</td>\n",
       "      <td>Others</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>Self</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>f</td>\n",
       "      <td>Black</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>m</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Parent</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>m</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>m</td>\n",
       "      <td>Asian</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>'Health care professional'</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>m</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Relative</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 age gender       ethnicity jaundice autism  \\\n",
       "0   1  1  1  1  0  0  1  1  0   0  26      f  White-European       no     no   \n",
       "1   1  1  0  1  0  0  0  1  0   1  24      m          Latino       no    yes   \n",
       "2   1  1  0  1  1  0  1  1  1   1  27      m          Latino      yes    yes   \n",
       "3   1  1  0  1  0  0  1  1  0   1  35      f  White-European       no    yes   \n",
       "5   1  1  1  1  1  0  1  1  1   1  36      m          Others      yes     no   \n",
       "6   0  1  0  0  0  0  0  1  0   0  17      f           Black       no     no   \n",
       "7   1  1  1  1  0  0  0  0  1   0  64      m  White-European       no     no   \n",
       "8   1  1  0  0  1  0  0  1  1   1  29      m  White-European       no     no   \n",
       "9   1  1  1  1  0  1  1  1  1   0  17      m           Asian      yes    yes   \n",
       "10  1  1  1  1  1  1  1  1  1   1  33      m  White-European       no     no   \n",
       "\n",
       "                      relation  ASD  \n",
       "0                         Self   NO  \n",
       "1                         Self   NO  \n",
       "2                       Parent  YES  \n",
       "3                         Self   NO  \n",
       "5                         Self  YES  \n",
       "6                         Self   NO  \n",
       "7                       Parent   NO  \n",
       "8                         Self   NO  \n",
       "9   'Health care professional'  YES  \n",
       "10                    Relative  YES  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correcting attribute names\n",
    "Clean_Autism_frame = Autism_frame.rename(index=str, columns={\"A1_Score\": \"A1\", \"A2_Score\": \"A2\", \"A3_Score\": \"A3\", \"A4_Score\": \"A4\", \"A5_Score\": \"A5\", \"A6_Score\": \"A6\", \"A7_Score\": \"A7\", \"A8_Score\": \"A8\", \"A9_Score\": \"A9\", \"A10_Score\": \"A10\", \"jundice\": \"jaundice\", \"austim\":\"autism\", \"contry_of_res\": \"country\", \"Class/ASD\": \"ASD\"})\n",
    "\n",
    "\n",
    "# Dropping attribute column 'age_descp' -> no significance\n",
    "Clean_Autism_frame = Clean_Autism_frame.drop(columns = ['age_desc']) # Now 19 attributes instead of 20\n",
    "\n",
    "\n",
    "# Replacing duplicate 'others' in ethnicity with 'Others'\n",
    "Clean_Autism_frame = Clean_Autism_frame.replace({'ethnicity': 'others'}, 'Others')\n",
    "\n",
    "\n",
    "# Replacing outlier in 'age'\n",
    "Clean_Autism_frame = Clean_Autism_frame.replace({'age': 383}, 38)\n",
    "\n",
    "\n",
    "# Remove samples with missing values\n",
    "Clean_Autism_frame = Clean_Autism_frame.dropna() # This leaves us with 609 samples instead of 704\n",
    "\n",
    "\n",
    "# ** Dropping attrs: country_of_res, used_app_before, age_desc, result **\n",
    "Clean_Autism_frame = Clean_Autism_frame.drop(columns = ['country', 'used_app_before', 'result']) # Now 19 attributes instead of 20\n",
    "\n",
    "\n",
    "# Printing first 10 rows of data frame\n",
    "Clean_Autism_frame.head(10)\n",
    "\n",
    "\n",
    "# Dimension of pandas DataFrame\n",
    "#print(Clean_Autism_frame.shape) # 609 by 17 -> 16 attributes, last column holds labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last preprocessing step is encoding categorical attributes**<br>\n",
    "*(ex in Gender: 'f' = 0, 'm' = 1) - the dimensions of our data matrix and labels can be seen below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim(Data_Matrix) =  (609, 16)\n",
      "Dim(Data_Labels) =  (609,)\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical attrs\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "attr_names = ['gender', 'ethnicity', 'jaundice', 'autism', 'relation', 'ASD']\n",
    "\n",
    "labelEncoder_X = LabelEncoder()\n",
    "\n",
    "for i in range(0,len(attr_names)):\n",
    "        Clean_Autism_frame[attr_names[i]] = labelEncoder_X.fit_transform(Clean_Autism_frame[attr_names[i]])\n",
    "\n",
    "# Data Matrix and Data Labels from clean pandas DataFrame        \n",
    "Matrix = Clean_Autism_frame.values\n",
    "Data_Matrix = Matrix[:,:-1]\n",
    "Data_Matrix = Data_Matrix.astype('int')\n",
    "Data_Labels = Matrix[:,-1]\n",
    "Data_Labels = Data_Labels.astype('int')\n",
    "#Data_Labels = np.reshape(Data_Labels, (609, 1))\n",
    "\n",
    "print(\"Dim(Data_Matrix) = \", Data_Matrix.shape)\n",
    "print(\"Dim(Data_Labels) = \", Data_Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing, using k = 7 cross validation<br>\n",
    "\n",
    "**Partitioning data and labels into folds, 87 samples per fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partitioning data into 7 folds\n",
    "X_folds = np.array([Data_Matrix[:87], Data_Matrix[87:174], Data_Matrix[174:261], Data_Matrix[261:348], Data_Matrix[348:435], Data_Matrix[435:522], Data_Matrix[522:]])\n",
    "\n",
    "# Partitioning labels into 7 folds\n",
    "label_fold1 = Data_Labels[0:87]\n",
    "label_fold2 = Data_Labels[87:174]\n",
    "label_fold3 = Data_Labels[174:261]\n",
    "label_fold4 = Data_Labels[261:348]\n",
    "label_fold5 = Data_Labels[348:435]\n",
    "label_fold6 = Data_Labels[435:522]\n",
    "label_fold7 = Data_Labels[522:]\n",
    "Labels_folds = np.array([label_fold1, label_fold2, label_fold3, label_fold4, label_fold5, label_fold6, label_fold7])\n",
    "\n",
    "# Store errors\n",
    "SVM_accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**SVM Training and Test Method**<br>\n",
    "Arguments are which folds to use as train, which fold to use as test. Uses sklearn's SVM classifier to fit based on training_data, training_labels. Then tests classifier using test fold and compares to test_labels for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def TrainAndTestSVM(in1, in2, in3, in4, in5, in6, in_test):\n",
    "    # Train Data and Labels\n",
    "    train_data = np.c_[X_folds[in1 - 1].T, X_folds[in2 - 1].T, X_folds[in3 - 1].T, X_folds[in4 - 1].T, X_folds[in5 - 1].T, X_folds[in6 - 1].T].T\n",
    "    train_labels = np.concatenate((Labels_folds[in1 - 1], Labels_folds[in2 - 1], Labels_folds[in3 - 1], Labels_folds[in4 - 1], Labels_folds[in5 - 1], Labels_folds[in6 - 1]))\n",
    "    \n",
    "    # Test Data and Labels\n",
    "    test_data = X_folds[in_test - 1]\n",
    "    test_labels = Labels_folds[in_test - 1]\n",
    "    \n",
    "    # SVM Train\n",
    "    clf = SVC(gamma = 'auto')\n",
    "    clf.fit(train_data, train_labels)\n",
    "    \n",
    "    # Test SVM\n",
    "    predictions = [] # Stores classifier predictions\n",
    "    for i in range(0, 87):\n",
    "        test_sample = test_data[i].reshape(1, -1)\n",
    "        prediction = clf.predict(test_sample)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration 1\n",
    "# Using folds 1, 2, 3, 4, 5, 6 as training, fold 7 as test\n",
    "iteration1_accuracy = TrainAndTestSVM(1, 2, 3, 4, 5, 6, 7)\n",
    "SVM_accuracies.append(iteration1_accuracy)\n",
    "\n",
    "# Iteration 2\n",
    "# Using folds 1, 2, 3, 4, 5, 7 as training, fold 6 as test\n",
    "iteration2_accuracy = TrainAndTestSVM(1, 2, 3, 4, 5, 7, 6)\n",
    "SVM_accuracies.append(iteration2_accuracy)\n",
    "\n",
    "# Iteration 3\n",
    "# Using folds 1, 2, 3, 4, 6, 7 as training, fold 5 as test\n",
    "iteration3_accuracy = TrainAndTestSVM(1, 2, 3, 4, 6, 7, 5)\n",
    "SVM_accuracies.append(iteration3_accuracy)\n",
    "\n",
    "# Iteration 4\n",
    "# Using folds 1, 2, 3, 5, 6, 7 as training, fold 4 as test\n",
    "iteration4_accuracy = TrainAndTestSVM(1, 2, 3, 5, 6, 7, 4)\n",
    "SVM_accuracies.append(iteration4_accuracy)\n",
    "\n",
    "# Iteration 5\n",
    "# Using folds 1, 2, 4, 5, 6, 7 as training, fold 3 as test\n",
    "iteration5_accuracy = TrainAndTestSVM(1, 2, 4, 5, 6, 7, 3)\n",
    "SVM_accuracies.append(iteration5_accuracy)\n",
    "\n",
    "# Iteration 6\n",
    "# Using folds 1, 3, 4, 5, 6, 7 as training, fold 2 as test\n",
    "iteration6_accuracy = TrainAndTestSVM(1, 3, 4, 5, 6, 7, 2)\n",
    "SVM_accuracies.append(iteration6_accuracy)\n",
    "\n",
    "# Iteration 7\n",
    "# Using folds 2, 3, 4, 5, 6, 7 as training, fold 1 as test\n",
    "iteration3_accuracy = TrainAndTestSVM(2, 3, 4, 5, 6, 7, 1)\n",
    "SVM_accuracies.append(iteration3_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing mean SVM accuracy across all k = 7 cross validation iterations**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy =  0.9178981937602628\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy = \", np.mean(SVM_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best SVM Training Model and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
