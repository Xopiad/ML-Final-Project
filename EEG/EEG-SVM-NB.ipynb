{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io.arff import loadarff\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess EEG Eye State DatasetÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14980 samples, 14 attrs, last column binary label\n",
    "\n",
    "# load the data. The function loadarff read most arff files and it can also read\n",
    "# files with missing data, representing the data points as NaNs. This \n",
    "# information is important for data preprocessing. The data used here \n",
    "# has no missing values\n",
    "EEG_Eye_State, meta = loadarff('EEG-Eye-State.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset: EEG_DATA\n",
       "\tAF3's type is numeric\n",
       "\tF7's type is numeric\n",
       "\tF3's type is numeric\n",
       "\tFC5's type is numeric\n",
       "\tT7's type is numeric\n",
       "\tP7's type is numeric\n",
       "\tO1's type is numeric\n",
       "\tO2's type is numeric\n",
       "\tP8's type is numeric\n",
       "\tT8's type is numeric\n",
       "\tFC6's type is numeric\n",
       "\tF4's type is numeric\n",
       "\tF8's type is numeric\n",
       "\tAF4's type is numeric\n",
       "\teyeDetection's type is nominal, range is ('0', '1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta contains information about the arff file, as shown below is the attributes\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>eyeDetection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329.23</td>\n",
       "      <td>4009.23</td>\n",
       "      <td>4289.23</td>\n",
       "      <td>4148.21</td>\n",
       "      <td>4350.26</td>\n",
       "      <td>4586.15</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4641.03</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4238.46</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4635.90</td>\n",
       "      <td>4393.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4328.72</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4296.41</td>\n",
       "      <td>4155.90</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4630.77</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4235.38</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4632.31</td>\n",
       "      <td>4396.41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4292.31</td>\n",
       "      <td>4151.28</td>\n",
       "      <td>4347.69</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4095.90</td>\n",
       "      <td>4627.69</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4244.10</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4398.46</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4321.03</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4284.10</td>\n",
       "      <td>4153.33</td>\n",
       "      <td>4345.64</td>\n",
       "      <td>4587.18</td>\n",
       "      <td>4093.33</td>\n",
       "      <td>4616.92</td>\n",
       "      <td>4202.56</td>\n",
       "      <td>4232.82</td>\n",
       "      <td>4209.74</td>\n",
       "      <td>4281.03</td>\n",
       "      <td>4628.21</td>\n",
       "      <td>4389.74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4319.49</td>\n",
       "      <td>4001.03</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4151.79</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4584.62</td>\n",
       "      <td>4089.74</td>\n",
       "      <td>4615.90</td>\n",
       "      <td>4212.31</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4201.03</td>\n",
       "      <td>4269.74</td>\n",
       "      <td>4625.13</td>\n",
       "      <td>4378.46</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4325.64</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4278.46</td>\n",
       "      <td>4143.08</td>\n",
       "      <td>4344.10</td>\n",
       "      <td>4583.08</td>\n",
       "      <td>4087.18</td>\n",
       "      <td>4614.87</td>\n",
       "      <td>4205.64</td>\n",
       "      <td>4230.26</td>\n",
       "      <td>4195.90</td>\n",
       "      <td>4266.67</td>\n",
       "      <td>4622.05</td>\n",
       "      <td>4380.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4010.77</td>\n",
       "      <td>4276.41</td>\n",
       "      <td>4139.49</td>\n",
       "      <td>4345.13</td>\n",
       "      <td>4584.10</td>\n",
       "      <td>4091.28</td>\n",
       "      <td>4608.21</td>\n",
       "      <td>4187.69</td>\n",
       "      <td>4229.74</td>\n",
       "      <td>4202.05</td>\n",
       "      <td>4273.85</td>\n",
       "      <td>4627.18</td>\n",
       "      <td>4389.74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.28</td>\n",
       "      <td>4276.92</td>\n",
       "      <td>4142.05</td>\n",
       "      <td>4344.10</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4092.82</td>\n",
       "      <td>4608.72</td>\n",
       "      <td>4194.36</td>\n",
       "      <td>4228.72</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4277.95</td>\n",
       "      <td>4637.44</td>\n",
       "      <td>4393.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AF3       F7       F3      FC5       T7       P7       O1       O2  \\\n",
       "0  4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
       "1  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
       "2  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
       "3  4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
       "4  4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
       "5  4321.03  4004.62  4284.10  4153.33  4345.64  4587.18  4093.33  4616.92   \n",
       "6  4319.49  4001.03  4280.51  4151.79  4343.59  4584.62  4089.74  4615.90   \n",
       "7  4325.64  4006.67  4278.46  4143.08  4344.10  4583.08  4087.18  4614.87   \n",
       "8  4326.15  4010.77  4276.41  4139.49  4345.13  4584.10  4091.28  4608.21   \n",
       "9  4326.15  4011.28  4276.92  4142.05  4344.10  4582.56  4092.82  4608.72   \n",
       "\n",
       "        P8       T8      FC6       F4       F8      AF4  eyeDetection  \n",
       "0  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85           0.0  \n",
       "1  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10           0.0  \n",
       "2  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23           0.0  \n",
       "3  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41           0.0  \n",
       "4  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46           0.0  \n",
       "5  4202.56  4232.82  4209.74  4281.03  4628.21  4389.74           0.0  \n",
       "6  4212.31  4226.67  4201.03  4269.74  4625.13  4378.46           0.0  \n",
       "7  4205.64  4230.26  4195.90  4266.67  4622.05  4380.51           0.0  \n",
       "8  4187.69  4229.74  4202.05  4273.85  4627.18  4389.74           0.0  \n",
       "9  4194.36  4228.72  4212.82  4277.95  4637.44  4393.33           0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EEG_Eye_State records the data of the arff file, accessible by attribute names\n",
    "# When add the EEG_Eye_State data to matrix, each element in the matrix has the type numpy.bytes_, therefore need to convert to\n",
    "# float or int type so data matrix could be manipulated without errors\n",
    "# Turn EEG_Eye_State into matrix of data\n",
    "Eye_State_data = np.array(EEG_Eye_State[meta.names()[0]].astype(float, copy = True)).reshape(14980,1)\n",
    "\n",
    "# Load attributes as type float\n",
    "for i in range(1,14):\n",
    "    Eye_State_data = np.c_[Eye_State_data, np.array(EEG_Eye_State[meta.names()[i]]).astype(float, copy = True)]\n",
    "\n",
    "# Load label as type int\n",
    "Eye_State_data = np.c_[Eye_State_data, np.array(EEG_Eye_State[meta.names()[14]]).astype(int, copy = True)]\n",
    "\n",
    "# Convert to pandas DataFrame for easier manipulation \n",
    "df = pd.DataFrame(data = Eye_State_data, columns = meta.names()[:])\n",
    "\n",
    "# First 10 samples\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim(EEG_Data_Matrix) =  (14980, 14)\n",
      "Dim(EEG_Data_Labels) =  (14980,)\n"
     ]
    }
   ],
   "source": [
    "# Data matrix, and labels array from pandas DataFrame\n",
    "EEG_Matrix = df.values\n",
    "\n",
    "# Shuffle the matrix by rows a few times\n",
    "for i in range(0, 14000):\n",
    "    np.random.shuffle(EEG_Matrix)\n",
    "\n",
    "EEG_Data_Matrix = EEG_Matrix[:,:-1]\n",
    "EEG_Data_Matrix = EEG_Data_Matrix.astype('float')\n",
    "EEG_Data_Labels = EEG_Matrix[:,-1]\n",
    "EEG_Data_Labels = EEG_Data_Labels.astype('int')\n",
    "\n",
    "print(\"Dim(EEG_Data_Matrix) = \", EEG_Data_Matrix.shape)\n",
    "print(\"Dim(EEG_Data_Labels) = \", EEG_Data_Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing, using k = 10 cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partitioning data and labels into folds, 1498 samples per fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partitioning data into 10 folds\n",
    "f = 1498\n",
    "EEG_Xfolds = np.array([EEG_Data_Matrix[:f], EEG_Data_Matrix[f:2*f], EEG_Data_Matrix[2*f:3*f], EEG_Data_Matrix[3*f:4*f], EEG_Data_Matrix[4*f:5*f], EEG_Data_Matrix[5*f:6*f], EEG_Data_Matrix[6*f:7*f], EEG_Data_Matrix[7*f:8*f], EEG_Data_Matrix[8*f:9*f], EEG_Data_Matrix[9*f:]])\n",
    "\n",
    "# Partitioning labels into 10 folds\n",
    "EEGlabel_fold1 = EEG_Data_Labels[0:f]\n",
    "EEGlabel_fold2 = EEG_Data_Labels[f:2*f]\n",
    "EEGlabel_fold3 = EEG_Data_Labels[2*f:3*f]\n",
    "EEGlabel_fold4 = EEG_Data_Labels[3*f:4*f]\n",
    "EEGlabel_fold5 = EEG_Data_Labels[4*f:5*f]\n",
    "EEGlabel_fold6 = EEG_Data_Labels[5*f:6*f]\n",
    "EEGlabel_fold7 = EEG_Data_Labels[6*f:7*f]\n",
    "EEGlabel_fold8 = EEG_Data_Labels[7*f:8*f]\n",
    "EEGlabel_fold9 = EEG_Data_Labels[8*f:9*f]\n",
    "EEGlabel_fold10 = EEG_Data_Labels[9*f:]\n",
    "\n",
    "EEG_Labels_folds = np.array([EEGlabel_fold1, EEGlabel_fold2, EEGlabel_fold3, EEGlabel_fold4, EEGlabel_fold5, EEGlabel_fold6, EEGlabel_fold7, EEGlabel_fold8, EEGlabel_fold9, EEGlabel_fold10])\n",
    "\n",
    "# Store errors\n",
    "EEG_SVM_accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM Training and Test Method**<br>\n",
    "Arguments are which folds to use as train, which fold to use as test. Uses sklearn's SVM classifier to fit based on training_data, training_labels. Then tests classifier using test fold and compares to test_labels for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Returns training and test scores\n",
    "def EEG_TrainTestSVM(f1, f2, f3, f4, f5, f6, f7, f8, f9, ftest):\n",
    "    # Train Data and Labels\n",
    "    train_data = np.c_[EEG_Xfolds[f1 - 1].T, EEG_Xfolds[f2 - 1].T, EEG_Xfolds[f3 - 1].T, EEG_Xfolds[f4 - 1].T, EEG_Xfolds[f5 - 1].T, EEG_Xfolds[f6 - 1].T, EEG_Xfolds[f7 - 1].T, EEG_Xfolds[f8 - 1].T, EEG_Xfolds[f9 - 1].T].T\n",
    "    train_labels = np.concatenate((EEG_Labels_folds[f1 - 1], EEG_Labels_folds[f2 - 1], EEG_Labels_folds[f3 - 1], EEG_Labels_folds[f4 - 1], EEG_Labels_folds[f5 - 1], EEG_Labels_folds[f6 - 1], EEG_Labels_folds[f7 - 1], EEG_Labels_folds[f8 - 1], EEG_Labels_folds[f9 - 1]))\n",
    "    \n",
    "    # Test Data and Labels\n",
    "    test_data = EEG_Xfolds[ftest - 1]\n",
    "    test_labels = EEG_Labels_folds[ftest - 1]\n",
    "    \n",
    "    # SVM Train\n",
    "    clf = SVC(gamma = 'auto')\n",
    "    #train_score = clf.fit(train_data, train_labels).score(train_data, train_labels)\n",
    "    clf.fit(train_data, train_labels)\n",
    "    \n",
    "    # Test SVM\n",
    "    predictions = [] # Stores classifier predictions\n",
    "    for i in range(0, 1498):\n",
    "        test_sample = test_data[i].reshape(1, -1)\n",
    "        prediction = clf.predict(test_sample)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5520694259012016, 0.5640854472630173, 0.5380507343124166, 0.5487316421895861, 0.5574098798397864, 0.5413885180240321, 0.5514018691588785, 0.5514018691588785, 0.5520694259012016, 0.5554072096128171]\n"
     ]
    }
   ],
   "source": [
    "# Iteration 1\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 8, 9 as training, fold 10 as test\n",
    "EEGiteration1_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "EEG_SVM_accuracies.append(EEGiteration1_accuracy)\n",
    "\n",
    "# Iteration 2\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 8, 10 as training, fold 9 as test\n",
    "EEGiteration2_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 8, 10, 9)\n",
    "EEG_SVM_accuracies.append(EEGiteration2_accuracy)\n",
    "\n",
    "# Iteration 3\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 9, 10 as training, fold 8 as test\n",
    "EEGiteration3_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 9, 10, 8)\n",
    "EEG_SVM_accuracies.append(EEGiteration3_accuracy)\n",
    "\n",
    "# Iteration 4\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 8, 9, 10 as training, fold 7 as test\n",
    "EEGiteration4_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 8, 9, 10, 7)\n",
    "EEG_SVM_accuracies.append(EEGiteration4_accuracy)\n",
    "\n",
    "# Iteration 5\n",
    "# Using folds 1, 2, 3, 4, 5, 7, 8, 9, 10 as training, fold 6 as test\n",
    "EEGiteration5_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 7, 8, 9, 10, 6)\n",
    "EEG_SVM_accuracies.append(EEGiteration5_accuracy)\n",
    "\n",
    "# Iteration 6\n",
    "# Using folds 1, 2, 3, 4, 6, 7, 8, 9, 10 as training, fold 5 as test\n",
    "EEGiteration6_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 6, 7, 8, 9, 10, 5)\n",
    "EEG_SVM_accuracies.append(EEGiteration6_accuracy)\n",
    "\n",
    "# Iteration 7\n",
    "# Using folds 1, 2, 3, 5, 6, 7, 8, 9, 10 as training, fold 4 as test\n",
    "EEGiteration7_accuracy = EEG_TrainTestSVM(1, 2, 3, 5, 6, 7, 8, 9, 10, 4)\n",
    "EEG_SVM_accuracies.append(EEGiteration7_accuracy)\n",
    "\n",
    "# Iteration 8\n",
    "# Using folds 1, 2, 4, 5, 6, 7, 8, 9, 10 as training, fold 3 as test\n",
    "EEGiteration8_accuracy = EEG_TrainTestSVM(1, 2, 4, 5, 6, 7, 8, 9, 10, 3)\n",
    "EEG_SVM_accuracies.append(EEGiteration8_accuracy)\n",
    "\n",
    "# Iteration 9\n",
    "# Using folds 1, 3, 4, 5, 6, 7, 8, 9, 10 as training, fold 2 as test\n",
    "EEGiteration9_accuracy = EEG_TrainTestSVM(1, 3, 4, 5, 6, 7, 8, 9, 10, 2)\n",
    "EEG_SVM_accuracies.append(EEGiteration9_accuracy)\n",
    "\n",
    "# Iteration 10\n",
    "# Using folds 2, 3, 4, 5, 6, 7, 8, 9, 10 as training, fold 1 as test\n",
    "EEGiteration10_accuracy = EEG_TrainTestSVM(2, 3, 4, 5, 6, 7, 8, 9, 10, 1)\n",
    "EEG_SVM_accuracies.append(EEGiteration10_accuracy)\n",
    "\n",
    "\n",
    "print(EEG_SVM_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing mean SVM accuracy across all k = 10 cross validation iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy =  0.5512016021361816\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy = \", np.mean(EEG_SVM_accuracies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
