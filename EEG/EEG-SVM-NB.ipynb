{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io.arff import loadarff\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess EEG Eye State DatasetÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14980 samples, 14 attrs, last column binary label\n",
    "\n",
    "# load the data. The function loadarff read most arff files and it can also read\n",
    "# files with missing data, representing the data points as NaNs. This \n",
    "# information is important for data preprocessing. The data used here \n",
    "# has no missing values\n",
    "EEG_Eye_State, meta = loadarff('EEG-Eye-State.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset: EEG_DATA\n",
       "\tAF3's type is numeric\n",
       "\tF7's type is numeric\n",
       "\tF3's type is numeric\n",
       "\tFC5's type is numeric\n",
       "\tT7's type is numeric\n",
       "\tP7's type is numeric\n",
       "\tO1's type is numeric\n",
       "\tO2's type is numeric\n",
       "\tP8's type is numeric\n",
       "\tT8's type is numeric\n",
       "\tFC6's type is numeric\n",
       "\tF4's type is numeric\n",
       "\tF8's type is numeric\n",
       "\tAF4's type is numeric\n",
       "\teyeDetection's type is nominal, range is ('0', '1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta contains information about the arff file, as shown below is the attributes\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>eyeDetection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329.23</td>\n",
       "      <td>4009.23</td>\n",
       "      <td>4289.23</td>\n",
       "      <td>4148.21</td>\n",
       "      <td>4350.26</td>\n",
       "      <td>4586.15</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4641.03</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4238.46</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4635.90</td>\n",
       "      <td>4393.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4328.72</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4296.41</td>\n",
       "      <td>4155.90</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4630.77</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4235.38</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4632.31</td>\n",
       "      <td>4396.41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4292.31</td>\n",
       "      <td>4151.28</td>\n",
       "      <td>4347.69</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4095.90</td>\n",
       "      <td>4627.69</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4244.10</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4398.46</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4321.03</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4284.10</td>\n",
       "      <td>4153.33</td>\n",
       "      <td>4345.64</td>\n",
       "      <td>4587.18</td>\n",
       "      <td>4093.33</td>\n",
       "      <td>4616.92</td>\n",
       "      <td>4202.56</td>\n",
       "      <td>4232.82</td>\n",
       "      <td>4209.74</td>\n",
       "      <td>4281.03</td>\n",
       "      <td>4628.21</td>\n",
       "      <td>4389.74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4319.49</td>\n",
       "      <td>4001.03</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4151.79</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4584.62</td>\n",
       "      <td>4089.74</td>\n",
       "      <td>4615.90</td>\n",
       "      <td>4212.31</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4201.03</td>\n",
       "      <td>4269.74</td>\n",
       "      <td>4625.13</td>\n",
       "      <td>4378.46</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4325.64</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4278.46</td>\n",
       "      <td>4143.08</td>\n",
       "      <td>4344.10</td>\n",
       "      <td>4583.08</td>\n",
       "      <td>4087.18</td>\n",
       "      <td>4614.87</td>\n",
       "      <td>4205.64</td>\n",
       "      <td>4230.26</td>\n",
       "      <td>4195.90</td>\n",
       "      <td>4266.67</td>\n",
       "      <td>4622.05</td>\n",
       "      <td>4380.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4010.77</td>\n",
       "      <td>4276.41</td>\n",
       "      <td>4139.49</td>\n",
       "      <td>4345.13</td>\n",
       "      <td>4584.10</td>\n",
       "      <td>4091.28</td>\n",
       "      <td>4608.21</td>\n",
       "      <td>4187.69</td>\n",
       "      <td>4229.74</td>\n",
       "      <td>4202.05</td>\n",
       "      <td>4273.85</td>\n",
       "      <td>4627.18</td>\n",
       "      <td>4389.74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.28</td>\n",
       "      <td>4276.92</td>\n",
       "      <td>4142.05</td>\n",
       "      <td>4344.10</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4092.82</td>\n",
       "      <td>4608.72</td>\n",
       "      <td>4194.36</td>\n",
       "      <td>4228.72</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4277.95</td>\n",
       "      <td>4637.44</td>\n",
       "      <td>4393.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AF3       F7       F3      FC5       T7       P7       O1       O2  \\\n",
       "0  4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
       "1  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
       "2  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
       "3  4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
       "4  4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
       "5  4321.03  4004.62  4284.10  4153.33  4345.64  4587.18  4093.33  4616.92   \n",
       "6  4319.49  4001.03  4280.51  4151.79  4343.59  4584.62  4089.74  4615.90   \n",
       "7  4325.64  4006.67  4278.46  4143.08  4344.10  4583.08  4087.18  4614.87   \n",
       "8  4326.15  4010.77  4276.41  4139.49  4345.13  4584.10  4091.28  4608.21   \n",
       "9  4326.15  4011.28  4276.92  4142.05  4344.10  4582.56  4092.82  4608.72   \n",
       "\n",
       "        P8       T8      FC6       F4       F8      AF4  eyeDetection  \n",
       "0  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85           0.0  \n",
       "1  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10           0.0  \n",
       "2  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23           0.0  \n",
       "3  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41           0.0  \n",
       "4  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46           0.0  \n",
       "5  4202.56  4232.82  4209.74  4281.03  4628.21  4389.74           0.0  \n",
       "6  4212.31  4226.67  4201.03  4269.74  4625.13  4378.46           0.0  \n",
       "7  4205.64  4230.26  4195.90  4266.67  4622.05  4380.51           0.0  \n",
       "8  4187.69  4229.74  4202.05  4273.85  4627.18  4389.74           0.0  \n",
       "9  4194.36  4228.72  4212.82  4277.95  4637.44  4393.33           0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EEG_Eye_State records the data of the arff file, accessible by attribute names\n",
    "# When add the EEG_Eye_State data to matrix, each element in the matrix has the type numpy.bytes_, therefore need to convert to\n",
    "# float or int type so data matrix could be manipulated without errors\n",
    "# Turn EEG_Eye_State into matrix of data\n",
    "Eye_State_data = np.array(EEG_Eye_State[meta.names()[0]].astype(float, copy = True)).reshape(14980,1)\n",
    "\n",
    "# Load attributes as type float\n",
    "for i in range(1,14):\n",
    "    Eye_State_data = np.c_[Eye_State_data, np.array(EEG_Eye_State[meta.names()[i]]).astype(float, copy = True)]\n",
    "\n",
    "# Load label as type int\n",
    "Eye_State_data = np.c_[Eye_State_data, np.array(EEG_Eye_State[meta.names()[14]]).astype(int, copy = True)]\n",
    "\n",
    "# Convert to pandas DataFrame for easier manipulation \n",
    "df = pd.DataFrame(data = Eye_State_data, columns = meta.names()[:])\n",
    "\n",
    "# First 10 samples\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following attempts to find the best model using sklearn's SVM classifier. The different implementations attempted are outlined below: **<br><br>\n",
    "\n",
    "*Note: all implementations use k = 10 fold cross validation*\n",
    "\n",
    "**Part 1**: Data includes all 14 original features, using sklearn SVM (with default parameters)<br>\n",
    "**Part 2**: Data feature dimensionality reduced with PCA, using sklearn's SVM (with default parameters) <br>\n",
    "**Part 3**: Using PCA feature reduced data from Part 2, using sklearn's SVM (with tuned parameters) Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First we extract our matrix of data including labels from the preprocessed pandas DataFrame above. After analyzing the data in the frame, there seems to be a large number of class '0' samples sectioned together, large number of class '1' samples sectioned together. To avoid biased folding later on, we shuffle the matrix holding all samples and their labels a few times. We then extract the data into a matrix and labels into a seperate vector.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim(EEG_Data_Matrix) =  (14980, 14)\n",
      "Dim(EEG_Data_Labels) =  (14980,)\n"
     ]
    }
   ],
   "source": [
    "# Matrix including samples and labels from pandas DataFrame\n",
    "EEG_Matrix = df.values\n",
    "\n",
    "# Shuffle the matrix by rows a few times\n",
    "for i in range(0, 100):\n",
    "    np.random.shuffle(EEG_Matrix)\n",
    "\n",
    "EEG_Data_Matrix = EEG_Matrix[:,:-1]\n",
    "EEG_Data_Matrix = EEG_Data_Matrix.astype('float')\n",
    "EEG_Data_Labels = EEG_Matrix[:,-1]\n",
    "EEG_Data_Labels = EEG_Data_Labels.astype('int')\n",
    "\n",
    "print(\"Dim(EEG_Data_Matrix) = \", EEG_Data_Matrix.shape)\n",
    "print(\"Dim(EEG_Data_Labels) = \", EEG_Data_Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next we define the main SVM training and testing method. The method below takes 13 arguments where arguments 1-9 are the fold indices to include for the training set, argument 10 is the fold index for the testing set. Argument 11 is a matrix holding all data samples without labels. Argument 12 is a vector of labels. This function needs this to partition into training and testing sets based on indices. Argument 13 is the sklearn classifier. **<br><br>\n",
    "**This method trains and returns the testing accuracy** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Training and test SVM, return test score\n",
    "def EEG_TrainTestSVM(f1, f2, f3, f4, f5, f6, f7, f8, f9, ftest, Data, Labels, clf):\n",
    "    # Train Data and Labels\n",
    "    train_data = np.c_[Data[f1 - 1].T, Data[f2 - 1].T, Data[f3 - 1].T, Data[f4 - 1].T, Data[f5 - 1].T, Data[f6 - 1].T, Data[f7 - 1].T, Data[f8 - 1].T, Data[f9 - 1].T].T\n",
    "    train_labels = np.concatenate((Labels[f1 - 1], Labels[f2 - 1], Labels[f3 - 1], Labels[f4 - 1], Labels[f5 - 1], Labels[f6 - 1], Labels[f7 - 1], Labels[f8 - 1], Labels[f9 - 1]))\n",
    "    \n",
    "    # Test Data and Labels\n",
    "    test_data = Data[ftest - 1]\n",
    "    test_labels = Labels[ftest - 1]\n",
    "    \n",
    "    clf.fit(train_data, train_labels)\n",
    "    \n",
    "    # Test SVM\n",
    "    predictions = [] # Stores classifier predictions\n",
    "    for i in range(0, 1498):\n",
    "        test_sample = test_data[i].reshape(1, -1)\n",
    "        prediction = clf.predict(test_sample)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Original 14 features and default sklearn SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we partition the data and labels into 10 folds for cross validation, 1498 samples per fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size per fold\n",
    "f = 1498\n",
    "\n",
    "# Partitioning data into 10 folds\n",
    "EEG_Xfolds = np.array([EEG_Data_Matrix[:f], EEG_Data_Matrix[f:2*f], EEG_Data_Matrix[2*f:3*f], EEG_Data_Matrix[3*f:4*f], EEG_Data_Matrix[4*f:5*f], EEG_Data_Matrix[5*f:6*f], EEG_Data_Matrix[6*f:7*f], EEG_Data_Matrix[7*f:8*f], EEG_Data_Matrix[8*f:9*f], EEG_Data_Matrix[9*f:]])\n",
    "\n",
    "# Partitioning labels into 10 folds\n",
    "EEGlabel_fold1 = EEG_Data_Labels[0:f]\n",
    "EEGlabel_fold2 = EEG_Data_Labels[f:2*f]\n",
    "EEGlabel_fold3 = EEG_Data_Labels[2*f:3*f]\n",
    "EEGlabel_fold4 = EEG_Data_Labels[3*f:4*f]\n",
    "EEGlabel_fold5 = EEG_Data_Labels[4*f:5*f]\n",
    "EEGlabel_fold6 = EEG_Data_Labels[5*f:6*f]\n",
    "EEGlabel_fold7 = EEG_Data_Labels[6*f:7*f]\n",
    "EEGlabel_fold8 = EEG_Data_Labels[7*f:8*f]\n",
    "EEGlabel_fold9 = EEG_Data_Labels[8*f:9*f]\n",
    "EEGlabel_fold10 = EEG_Data_Labels[9*f:]\n",
    "\n",
    "EEG_Labels_folds = np.array([EEGlabel_fold1, EEGlabel_fold2, EEGlabel_fold3, EEGlabel_fold4, EEGlabel_fold5, EEGlabel_fold6, EEGlabel_fold7, EEGlabel_fold8, EEGlabel_fold9, EEGlabel_fold10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we define our sklearn SVM classifier with default parameters as an argument to our train/test method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passed to our method in cross validation\n",
    "clf = SVC(gamma = 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracies for Iterations 1-10:  [0.5700934579439252, 0.5540720961281709, 0.548064085447263, 0.5674232309746329, 0.5527369826435247, 0.5427236315086782, 0.5487316421895861, 0.5433911882510013, 0.5534045393858478, 0.5313751668891856]\n"
     ]
    }
   ],
   "source": [
    "# Store errors\n",
    "EEG_SVM_accuracies = []\n",
    "\n",
    "# Iteration 1\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 8, 9 as training, fold 10 as test\n",
    "EEGiteration1_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, EEG_Xfolds, EEG_Labels_folds, clf)\n",
    "EEG_SVM_accuracies.append(EEGiteration1_accuracy)\n",
    "\n",
    "# Iteration 2\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 8, 10 as training, fold 9 as test\n",
    "EEGiteration2_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 8, 10, 9, EEG_Xfolds, EEG_Labels_folds, clf)\n",
    "EEG_SVM_accuracies.append(EEGiteration2_accuracy)\n",
    "\n",
    "# Iteration 3\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 9, 10 as training, fold 8 as test\n",
    "EEGiteration3_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 9, 10, 8, EEG_Xfolds, EEG_Labels_folds, clf)\n",
    "EEG_SVM_accuracies.append(EEGiteration3_accuracy)\n",
    "\n",
    "# Iteration 4\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 8, 9, 10 as training, fold 7 as test\n",
    "EEGiteration4_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 8, 9, 10, 7, EEG_Xfolds, EEG_Labels_folds, clf)\n",
    "EEG_SVM_accuracies.append(EEGiteration4_accuracy)\n",
    "\n",
    "# Iteration 5\n",
    "# Using folds 1, 2, 3, 4, 5, 7, 8, 9, 10 as training, fold 6 as test\n",
    "EEGiteration5_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 7, 8, 9, 10, 6, EEG_Xfolds, EEG_Labels_folds, clf)\n",
    "EEG_SVM_accuracies.append(EEGiteration5_accuracy)\n",
    "\n",
    "# Iteration 6\n",
    "# Using folds 1, 2, 3, 4, 6, 7, 8, 9, 10 as training, fold 5 as test\n",
    "EEGiteration6_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 6, 7, 8, 9, 10, 5, EEG_Xfolds, EEG_Labels_folds, clf)\n",
    "EEG_SVM_accuracies.append(EEGiteration6_accuracy)\n",
    "\n",
    "# Iteration 7\n",
    "# Using folds 1, 2, 3, 5, 6, 7, 8, 9, 10 as training, fold 4 as test\n",
    "EEGiteration7_accuracy = EEG_TrainTestSVM(1, 2, 3, 5, 6, 7, 8, 9, 10, 4, EEG_Xfolds, EEG_Labels_folds, clf)\n",
    "EEG_SVM_accuracies.append(EEGiteration7_accuracy)\n",
    "\n",
    "# Iteration 8\n",
    "# Using folds 1, 2, 4, 5, 6, 7, 8, 9, 10 as training, fold 3 as test\n",
    "EEGiteration8_accuracy = EEG_TrainTestSVM(1, 2, 4, 5, 6, 7, 8, 9, 10, 3, EEG_Xfolds, EEG_Labels_folds, clf)\n",
    "EEG_SVM_accuracies.append(EEGiteration8_accuracy)\n",
    "\n",
    "# Iteration 9\n",
    "# Using folds 1, 3, 4, 5, 6, 7, 8, 9, 10 as training, fold 2 as test\n",
    "EEGiteration9_accuracy = EEG_TrainTestSVM(1, 3, 4, 5, 6, 7, 8, 9, 10, 2, EEG_Xfolds, EEG_Labels_folds, clf)\n",
    "EEG_SVM_accuracies.append(EEGiteration9_accuracy)\n",
    "\n",
    "# Iteration 10\n",
    "# Using folds 2, 3, 4, 5, 6, 7, 8, 9, 10 as training, fold 1 as test\n",
    "EEGiteration10_accuracy = EEG_TrainTestSVM(2, 3, 4, 5, 6, 7, 8, 9, 10, 1, EEG_Xfolds, EEG_Labels_folds, clf)\n",
    "EEG_SVM_accuracies.append(EEGiteration10_accuracy)\n",
    "\n",
    "\n",
    "print(\"Test Accuracies for Iterations 1-10: \", EEG_SVM_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing mean SVM accuracy across all k = 10 cross validation iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy =  0.5512016021361815\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy = \", np.mean(EEG_SVM_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First SVM Model Discussion**<br>\n",
    "As seen above, the average accuracy across k = 10 fold cross validation is 0.55. This is not a good value and can be due to a few things. First, the SVM parameters for our training model were set to auto default. Since our data might be considered inseperable, it is crucial to wisely choose the kernel trick, and penalty parameter (C) to best seperate our data. This will allow for seperation of data in higher dimension but also tuning the C parameter creates a small-margin hyperplane and a larger value of C creates a larger-margin hyperplane. Manipulating this can help take care of outliers closer to the seperating hyperplane for better classification. The last paramter to tune would be gamma. The range for gamma is 0.1 to 1.0 where 1.0 would usually cause overfitting of the model. In this case, we experiment with gamma set to 0.1 to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Using PCA for Top 3 Principal Components and Default Sklearn SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First we show how many top k principal components will capture at least 95% of the data for feature reduction**<br>\n",
    "FIX THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we extract the data and labels from the already shuffled matrix from Part 1 (for better comparison between models). The data is mean centered. Then we compute the singular value decomposition to obtain the top three principal components from the sigma diagonal matrix. We use the three principal components to obtain the PCA based feauture representation X_Tilde of our mean centered data. Our data dimension is now 14980 by 3.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14980, 14)\n",
      "(14980,)\n",
      "(14, 14980)\n",
      "(14, 14980)\n",
      "(14980, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split data and labels    \n",
    "EEG_PCA_Data = EEG_Matrix[:,:-1]\n",
    "EEG_PCA_Data = EEG_PCA_Data.astype('float')\n",
    "EEG_PCA_Labels = EEG_Matrix[:,-1]\n",
    "EEG_PCA_Labels = EEG_PCA_Labels.astype('int')\n",
    "\n",
    "print(EEG_PCA_Data.shape)\n",
    "print(EEG_PCA_Labels.shape)\n",
    "\n",
    "# Arranging each sample is a column in data matrix\n",
    "X = EEG_PCA_Data.T # Data matrix\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# Computation empirical mean - vector and tiled matrix\n",
    "mean_vec = X.mean(axis = 1)\n",
    "mean_mat = np.tile(mean_vec.reshape(X.shape[0],1),[1,X.shape[1]])\n",
    "\n",
    "# Centered data matrix\n",
    "centered_X = X - mean_mat\n",
    "\n",
    "print(centered_X.shape)\n",
    "\n",
    "# SVD of centered data\n",
    "U, s, Vh = np.linalg.svd(centered_X)\n",
    "\n",
    "# Top two principal components of centered data matrix\n",
    "U_2 = U[:,0:3]\n",
    "\n",
    "# Compute the PCA-based features\n",
    "X_tilde = U_2.T@centered_X\n",
    "\n",
    "X_tilde = X_tilde.T\n",
    "\n",
    "print(X_tilde.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we partition our new feature reduced data and labels into folds, 1498 samples per fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partitioning data into 10 folds\n",
    "f = 1498\n",
    "\n",
    "PCA_EEG_Xfolds = np.array([X_tilde[:f], X_tilde[f:2*f], X_tilde[2*f:3*f], X_tilde[3*f:4*f], X_tilde[4*f:5*f], X_tilde[5*f:6*f], X_tilde[6*f:7*f], X_tilde[7*f:8*f], X_tilde[8*f:9*f], X_tilde[9*f:]])\n",
    "\n",
    "# Partitioning labels into 10 folds\n",
    "EEGlabel_fold1 = EEG_PCA_Labels[0:f]\n",
    "EEGlabel_fold2 = EEG_PCA_Labels[f:2*f]\n",
    "EEGlabel_fold3 = EEG_PCA_Labels[2*f:3*f]\n",
    "EEGlabel_fold4 = EEG_PCA_Labels[3*f:4*f]\n",
    "EEGlabel_fold5 = EEG_PCA_Labels[4*f:5*f]\n",
    "EEGlabel_fold6 = EEG_PCA_Labels[5*f:6*f]\n",
    "EEGlabel_fold7 = EEG_PCA_Labels[6*f:7*f]\n",
    "EEGlabel_fold8 = EEG_PCA_Labels[7*f:8*f]\n",
    "EEGlabel_fold9 = EEG_PCA_Labels[8*f:9*f]\n",
    "EEGlabel_fold10 = EEG_PCA_Labels[9*f:]\n",
    "\n",
    "EEG_PCALabels_folds = np.array([EEGlabel_fold1, EEGlabel_fold2, EEGlabel_fold3, EEGlabel_fold4, EEGlabel_fold5, EEGlabel_fold6, EEGlabel_fold7, EEGlabel_fold8, EEGlabel_fold9, EEGlabel_fold10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we again define our sklearn SVM classifier with default parameters as an argument to our train/test method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passed to our method in cross validation\n",
    "clf = SVC(gamma = 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation iterations using default SVM w/ PCA Dimension Reduced Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Model: Test Accuracies for Iterations 1-10:  [0.6068090787716955, 0.5921228304405874, 0.5934579439252337, 0.6101468624833111, 0.5967957276368492, 0.5921228304405874, 0.5961281708945261, 0.5907877169559412, 0.6088117489986649, 0.5801068090787717]\n"
     ]
    }
   ],
   "source": [
    "# Store errors\n",
    "EEG_SVM2_accuracies = []\n",
    "\n",
    "# Iteration 1\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 8, 9 as training, fold 10 as test\n",
    "EEGiteration1_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf)\n",
    "EEG_SVM2_accuracies.append(EEGiteration1_accuracy)\n",
    "\n",
    "# Iteration 2\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 8, 10 as training, fold 9 as test\n",
    "EEGiteration2_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 8, 10, 9, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf)\n",
    "EEG_SVM2_accuracies.append(EEGiteration2_accuracy)\n",
    "\n",
    "# Iteration 3\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 9, 10 as training, fold 8 as test\n",
    "EEGiteration3_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 9, 10, 8, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf)\n",
    "EEG_SVM2_accuracies.append(EEGiteration3_accuracy)\n",
    "\n",
    "# Iteration 4\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 8, 9, 10 as training, fold 7 as test\n",
    "EEGiteration4_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 8, 9, 10, 7, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf)\n",
    "EEG_SVM2_accuracies.append(EEGiteration4_accuracy)\n",
    "\n",
    "# Iteration 5\n",
    "# Using folds 1, 2, 3, 4, 5, 7, 8, 9, 10 as training, fold 6 as test\n",
    "EEGiteration5_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 7, 8, 9, 10, 6, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf)\n",
    "EEG_SVM2_accuracies.append(EEGiteration5_accuracy)\n",
    "\n",
    "# Iteration 6\n",
    "# Using folds 1, 2, 3, 4, 6, 7, 8, 9, 10 as training, fold 5 as test\n",
    "EEGiteration6_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 6, 7, 8, 9, 10, 5, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf)\n",
    "EEG_SVM2_accuracies.append(EEGiteration6_accuracy)\n",
    "\n",
    "# Iteration 7\n",
    "# Using folds 1, 2, 3, 5, 6, 7, 8, 9, 10 as training, fold 4 as test\n",
    "EEGiteration7_accuracy = EEG_TrainTestSVM(1, 2, 3, 5, 6, 7, 8, 9, 10, 4, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf)\n",
    "EEG_SVM2_accuracies.append(EEGiteration7_accuracy)\n",
    "\n",
    "# Iteration 8\n",
    "# Using folds 1, 2, 4, 5, 6, 7, 8, 9, 10 as training, fold 3 as test\n",
    "EEGiteration8_accuracy = EEG_TrainTestSVM(1, 2, 4, 5, 6, 7, 8, 9, 10, 3, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf)\n",
    "EEG_SVM2_accuracies.append(EEGiteration8_accuracy)\n",
    "\n",
    "# Iteration 9\n",
    "# Using folds 1, 3, 4, 5, 6, 7, 8, 9, 10 as training, fold 2 as test\n",
    "EEGiteration9_accuracy = EEG_TrainTestSVM(1, 3, 4, 5, 6, 7, 8, 9, 10, 2, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf)\n",
    "EEG_SVM2_accuracies.append(EEGiteration9_accuracy)\n",
    "\n",
    "# Iteration 10\n",
    "# Using folds 2, 3, 4, 5, 6, 7, 8, 9, 10 as training, fold 1 as test\n",
    "EEGiteration10_accuracy = EEG_TrainTestSVM(2, 3, 4, 5, 6, 7, 8, 9, 10, 1, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf)\n",
    "EEG_SVM2_accuracies.append(EEGiteration10_accuracy)\n",
    "\n",
    "print(\"Second Model: Test Accuracies for Iterations 1-10: \", EEG_SVM2_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing mean SVM accuracy across all k = 10 cross validation iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy =  0.5967289719626169\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy = \", np.mean(EEG_SVM2_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second SVM Model Discussion**<br>\n",
    "FIX THIS<br>\n",
    "As seen above, the average accuracy across k = 10 fold cross validation is 0.55. This is not a good value and can be due to a few things. First, the SVM parameters for our training model were set to auto default. Since our data might be considered inseperable, it is crucial to wisely choose the kernel trick, and penalty parameter (C) to best seperate our data. This will allow for seperation of data in higher dimension but also tuning the C parameter creates a small-margin hyperplane and a larger value of C creates a larger-margin hyperplane. Manipulating this can help take care of outliers closer to the seperating hyperplane for better classification. The last paramter to tune would be gamma. The range for gamma is 0.1 to 1.0 where 1.0 would usually cause overfitting of the model. In this case, we experiment with gamma set to 0.1 to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Using PCA Feature Reduced Data from Part 2 and Tuned Parameters Sklearn SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For this model, we do not need to manipulate the data matrix or vector of labels since we will just reuse from Part 2. Essentially, the only difference here will be different sklearn SVM parameters instead of the default. See the tuned classifier below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier w/ tuned parameters\n",
    "clf3 = SVC(C=1.0, gamma = 0.1, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation iterations using SVM w/ tuned parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third Model: Test Accuracies for Iterations 1-10:  [0.6535380507343124, 0.6602136181575434, 0.6475300400534045, 0.6455273698264352, 0.6522029372496663, 0.6448598130841121, 0.6515353805073432, 0.6615487316421896, 0.6468624833110814, 0.6468624833110814]\n"
     ]
    }
   ],
   "source": [
    "# Store errors\n",
    "EEG_SVM3_accuracies = []\n",
    "\n",
    "# Iteration 1\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 8, 9 as training, fold 10 as test\n",
    "EEGiteration1_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf3)\n",
    "EEG_SVM3_accuracies.append(EEGiteration1_accuracy)\n",
    "\n",
    "# Iteration 2\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 8, 10 as training, fold 9 as test\n",
    "EEGiteration2_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 8, 10, 9, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf3)\n",
    "EEG_SVM3_accuracies.append(EEGiteration2_accuracy)\n",
    "\n",
    "# Iteration 3\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 7, 9, 10 as training, fold 8 as test\n",
    "EEGiteration3_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 7, 9, 10, 8, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf3)\n",
    "EEG_SVM3_accuracies.append(EEGiteration3_accuracy)\n",
    "\n",
    "# Iteration 4\n",
    "# Using folds 1, 2, 3, 4, 5, 6, 8, 9, 10 as training, fold 7 as test\n",
    "EEGiteration4_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 6, 8, 9, 10, 7, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf3)\n",
    "EEG_SVM3_accuracies.append(EEGiteration4_accuracy)\n",
    "\n",
    "# Iteration 5\n",
    "# Using folds 1, 2, 3, 4, 5, 7, 8, 9, 10 as training, fold 6 as test\n",
    "EEGiteration5_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 5, 7, 8, 9, 10, 6, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf3)\n",
    "EEG_SVM3_accuracies.append(EEGiteration5_accuracy)\n",
    "\n",
    "# Iteration 6\n",
    "# Using folds 1, 2, 3, 4, 6, 7, 8, 9, 10 as training, fold 5 as test\n",
    "EEGiteration6_accuracy = EEG_TrainTestSVM(1, 2, 3, 4, 6, 7, 8, 9, 10, 5, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf3)\n",
    "EEG_SVM3_accuracies.append(EEGiteration6_accuracy)\n",
    "\n",
    "# Iteration 7\n",
    "# Using folds 1, 2, 3, 5, 6, 7, 8, 9, 10 as training, fold 4 as test\n",
    "EEGiteration7_accuracy = EEG_TrainTestSVM(1, 2, 3, 5, 6, 7, 8, 9, 10, 4, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf3)\n",
    "EEG_SVM3_accuracies.append(EEGiteration7_accuracy)\n",
    "\n",
    "# Iteration 8\n",
    "# Using folds 1, 2, 4, 5, 6, 7, 8, 9, 10 as training, fold 3 as test\n",
    "EEGiteration8_accuracy = EEG_TrainTestSVM(1, 2, 4, 5, 6, 7, 8, 9, 10, 3, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf3)\n",
    "EEG_SVM3_accuracies.append(EEGiteration8_accuracy)\n",
    "\n",
    "# Iteration 9\n",
    "# Using folds 1, 3, 4, 5, 6, 7, 8, 9, 10 as training, fold 2 as test\n",
    "EEGiteration9_accuracy = EEG_TrainTestSVM(1, 3, 4, 5, 6, 7, 8, 9, 10, 2, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf3)\n",
    "EEG_SVM3_accuracies.append(EEGiteration9_accuracy)\n",
    "\n",
    "# Iteration 10\n",
    "# Using folds 2, 3, 4, 5, 6, 7, 8, 9, 10 as training, fold 1 as test\n",
    "EEGiteration10_accuracy = EEG_TrainTestSVM(2, 3, 4, 5, 6, 7, 8, 9, 10, 1, PCA_EEG_Xfolds, EEG_PCALabels_folds, clf3)\n",
    "EEG_SVM3_accuracies.append(EEGiteration10_accuracy)\n",
    "\n",
    "print(\"Third Model: Test Accuracies for Iterations 1-10: \", EEG_SVM3_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing mean SVM accuracy across all k = 10 cross validation iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy =  0.651068090787717\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy = \", np.mean(EEG_SVM3_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third SVM Model Discussion**<br>\n",
    "FIX THIS<br>\n",
    "As seen above, the average accuracy across k = 10 fold cross validation is 0.55. This is not a good value and can be due to a few things. First, the SVM parameters for our training model were set to auto default. Since our data might be considered inseperable, it is crucial to wisely choose the kernel trick, and penalty parameter (C) to best seperate our data. This will allow for seperation of data in higher dimension but also tuning the C parameter creates a small-margin hyperplane and a larger value of C creates a larger-margin hyperplane. Manipulating this can help take care of outliers closer to the seperating hyperplane for better classification. The last paramter to tune would be gamma. The range for gamma is 0.1 to 1.0 where 1.0 would usually cause overfitting of the model. In this case, we experiment with gamma set to 0.1 to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Talk about the SVM parameters and their affect on the classification test accuracy\n",
    "# Also mention also possible factors to this low score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
